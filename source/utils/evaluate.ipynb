{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjJCGbbbXdRq",
        "outputId": "89287170-959c-4bc0-d9f8-dc8b745b1116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FYzB7vKcXWcs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\andro\\anaconda3\\envs\\NLP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from retrieval import Book, generate_embeddings, get_embedding_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "CwkBeunoXWcv",
        "outputId": "0d5d9255-866b-4857-fb35-967a8d35be91"
      },
      "outputs": [],
      "source": [
        "hf_token = \"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\"\n",
        "from transformers import LlamaForCausalLM, LlamaTokenizer, pipeline\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LlamaForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", token=hf_token, torch_dtype=torch.bfloat16).to(device)\n",
        "tokenizer = LlamaTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", token=hf_token, torch_dtype=torch.bfloat16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8w9fh8eOXWcv"
      },
      "outputs": [],
      "source": [
        "text_generator = pipeline('text-generation',\n",
        "                          model=model,\n",
        "                          tokenizer=tokenizer,\n",
        "                          torch_dtype=torch.bfloat16,\n",
        "                          device=0,\n",
        "                          # device_map=\"auto\",\n",
        "                          do_sample=True,\n",
        "                          top_k=10,\n",
        "                          num_return_sequences=1,\n",
        "                          max_length=3_000,\n",
        "                          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xrOUqpKdlFy",
        "outputId": "9bc9324c-4e4b-43d0-b1ca-fae595dba7c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(model.device)\n",
        "print(text_generator.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eGCFS5-D87ZL"
      },
      "outputs": [],
      "source": [
        "class Character_chat:\n",
        "    def __init__(self, character_name, book, book_name, add_quotes=True):\n",
        "\n",
        "        self.character_name = character_name\n",
        "        self.system_prompt = f\"\"\"\n",
        "            You are {character_name}, a fictional character from {book_name}.\n",
        "            The user question is directed at the character.\n",
        "            Respond in a single paragraph. \n",
        "            When answering questions, use the book excerpt enclosed by triple backquotes for context.\n",
        "            IMPORTANT: You must ALWAYS only respond IN CHARACTER.\n",
        "            The user's prompt begins with 'user:'\n",
        "            The character's reponses begin with '{character_name}:'\n",
        "            \"\"\"\n",
        "        self.lines = book.get_character_lines(character_name)\n",
        "        if add_quotes:\n",
        "          self.character_quotes = \"\\n\".join([f\"{character_name}: \" + line for line in self.lines[:10]])\n",
        "          self.system_prompt += f\"Here are some examples of {character_name}'s dialogue:\\n\"\n",
        "          self.system_prompt += self.character_quotes\n",
        "          self.system_prompt += \"\\n\\n\"\n",
        "\n",
        "\n",
        "        # self.prompt = \"\"\"<s>[INST]\\n\n",
        "        #                 <<SYS>>\\n\n",
        "        #                   {system_prompt}\\n\n",
        "        #                 <</SYS>>\\n\\n\n",
        "        #                 user:{user_input}\\n\\n\n",
        "        #                 [/INST]\"\"\"\n",
        "        \n",
        "        self.prompt = \"\"\"<|system|>\n",
        "                          {system_prompt}\"\"\"\n",
        "        \n",
        "        if add_quotes:\n",
        "            self.prompt += \"\"\"```\n",
        "                         {context}\n",
        "                         ```\"\"\"\n",
        "                          \n",
        "        self.prompt +=   \"\"\"</s>\n",
        "                        <|user|>:\n",
        "                        {user_input}</s>\n",
        "                        <|{character_name}|>:\"\"\"\n",
        "        \n",
        "        self.retriever = book.get_retriever(k=2)\n",
        "\n",
        "\n",
        "    def get_response(self, user_input):\n",
        "        context = self.retriever.invoke(user_input)\n",
        "        input = self.prompt.format(user_input=user_input,\n",
        "                                   system_prompt=self.system_prompt,\n",
        "                                   context=context,\n",
        "                                   character_name=self.character_name)\n",
        "        # print(input)\n",
        "        output = text_generator(input)\n",
        "        res = output[0]['generated_text'].split(f\"<|{self.character_name}|>:\")[-1]\n",
        "        print(res)\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G_b8RnXYNxeg"
      },
      "outputs": [],
      "source": [
        "def eval_response(user_input, chat, book, measure):\n",
        "\n",
        "  res = chat.get_response(user_input)\n",
        "  test_embeddings = generate_embeddings(book.get_best_sentences(user_input, chat.character_name))\n",
        "  res_embedding = generate_embeddings(res)\n",
        "  score = 0\n",
        "  for embedding in test_embeddings:\n",
        "    score += measure(embedding, res_embedding)\n",
        "  return score / len(test_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCZAwVIZUEnU",
        "outputId": "dc616e36-82bf-4fbd-d696-196c3d866c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "I do not know what you are talking about.\n",
            "\n",
            "                        I do not remember escaping them, but I am certain they tried to capture me. But before I was able to flee, I managed to board a pirate ship and was forced to spend two days in their galleys. They had a compelled valour and had me boarded, but I managed to escape their ship and return home with the letters.\n",
            "0.15291938781738282 0.24047233760356904\n"
          ]
        }
      ],
      "source": [
        "book_path = \"D:\\\\Faks\\\\NLP\\\\Project\\\\data\\\\hamlet.txt\"\n",
        "book = Book(book_path)\n",
        "# print(book.get_characters())\n",
        "\n",
        "hamlet_chat_simple = Character_chat(character_name=\"HAMLET\", book=book, book_name=\"HAMLET\", add_quotes=False)\n",
        "hamlet_chat_with_quotes = Character_chat(character_name=\"HAMLET\", book=book, book_name=\"HAMLET\", add_quotes=True)\n",
        "\n",
        "user_input = \"How did you escape the pirates?\"\n",
        "\n",
        "measure = get_embedding_similarity\n",
        "score1 = eval_response(user_input, hamlet_chat_simple, book=book, measure=get_embedding_similarity)\n",
        "score2 = eval_response(user_input, hamlet_chat_with_quotes, book=book, measure=get_embedding_similarity)\n",
        "print(score1, score2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTSEC_l_oFj4",
        "outputId": "31353a1f-583e-4ca0-d46b-01a94b2443f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|system|>\n",
            "                          \n",
            "            You are SIR ROBERT CHILTERN, a fictional character from IDEAL HUSBAND.\n",
            "            Respond in a single paragraph. \n",
            "            When answering questions, use the book excerpt enclosed by triple backquotes for context.\n",
            "            Do not mention the text received directly in your response.\n",
            "            IMPORTANT: When you are asked a question or told something you must only respond IN CHARACTER.\n",
            "            The user's prompt begins with 'user:'\n",
            "            The character's reponses begin with 'SIR ROBERT CHILTERN:'\n",
            "            </s>\n",
            "                        <|user|>:\n",
            "                        Do you know anything about Mrs Cheveley's involvment with the Suez canal company?</s>\n",
            "                        <|SIR ROBERT CHILTERN|>:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\andro\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:670: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                        \n",
            "                        As the book progresses, it becomes evident that Mrs Cheveley's involvement with the Suez canal company is a crucial part of her character. The company's involvement with British imperialism, in particular, is seen as a source of conflict, with Mrs Cheveley becoming increasingly disenchanted with it. The company's success in the region and its expansionist aims, along with her husband's investment in it, are cited as contributing to her unhappiness. The book also touches on her personal life and her relationships with other characters, with her husband and daughter becoming increasingly distant as their own lives and interests diverge from her own. Ultimately, Mrs Cheveley's involvement with the Suez company becomes a central part of her personality, and her disillusionment with it is a driving force behind her character development in the novel.\n",
            "<|system|>\n",
            "                          \n",
            "            You are SIR ROBERT CHILTERN, a fictional character from IDEAL HUSBAND.\n",
            "            Respond in a single paragraph. \n",
            "            When answering questions, use the book excerpt enclosed by triple backquotes for context.\n",
            "            Do not mention the text received directly in your response.\n",
            "            IMPORTANT: When you are asked a question or told something you must only respond IN CHARACTER.\n",
            "            The user's prompt begins with 'user:'\n",
            "            The character's reponses begin with 'SIR ROBERT CHILTERN:'\n",
            "            Here are some examples of SIR ROBERT CHILTERN's dialogue:\n",
            "SIR ROBERT CHILTERN: Good evening, Lady Markby!  I hope you have brought Sir John with you?\n",
            "SIR ROBERT CHILTERN: I hope not, Lady Markby.  At any rate we do our best to waste the public time, don’t we?  But who is this charming person you have been kind enough to bring to us?\n",
            "SIR ROBERT CHILTERN: Mrs. Cheveley?  I seem to know the name.\n",
            "SIR ROBERT CHILTERN: Ah! yes.  I think I know whom you mean.\n",
            "SIR ROBERT CHILTERN: If there is not, the Ambassador will certainly have to be recalled.  Pray point out Mrs. Cheveley to me.  I should like to see her.\n",
            "SIR ROBERT CHILTERN: Every one is dying to know the brilliant Mrs. Cheveley.  Our attachés at Vienna write to us about nothing else.\n",
            "SIR ROBERT CHILTERN: Really?\n",
            "SIR ROBERT CHILTERN: And what prizes did you get, Mrs. Cheveley?\n",
            "SIR ROBERT CHILTERN: I am sure they were for something charming!\n",
            "SIR ROBERT CHILTERN: What an appalling philosophy that sounds!  To attempt to classify you, Mrs. Cheveley, would be an impertinence.  But may I ask, at heart, are you an optimist or a pessimist?  Those seem to be the only two fashionable religions left to us nowadays.\n",
            "\n",
            "```\n",
            "                         [Document(page_content='SIR ROBERT CHILTERN.  Yes.  But the Suez Canal was a very great and\\nsplendid undertaking.  It gave us our direct route to India.  It had\\nimperial value.  It was necessary that we should have control.  This\\nArgentine scheme is a commonplace Stock Exchange swindle.\\n\\nMRS. CHEVELEY.  A speculation, Sir Robert!  A brilliant, daring\\nspeculation.', metadata={'source': 'D:\\\\Faks\\\\NLP\\\\Project\\\\data\\\\ideal_husband.txt'}), Document(page_content='MRS. CHEVELEY.  Oh, I like tedious, practical subjects.  What I don’t\\nlike are tedious, practical people.  There is a wide difference.\\nBesides, you are interested, I know, in International Canal schemes.  You\\nwere Lord Radley’s secretary, weren’t you, when the Government bought the\\nSuez Canal shares?', metadata={'source': 'D:\\\\Faks\\\\NLP\\\\Project\\\\data\\\\ideal_husband.txt'}), Document(page_content='MRS. CHEVELEY.  Quite seriously.  I want to talk to you about a great\\npolitical and financial scheme, about this Argentine Canal Company, in\\nfact.\\n\\nSIR ROBERT CHILTERN.  What a tedious, practical subject for you to talk\\nabout, Mrs. Cheveley!', metadata={'source': 'D:\\\\Faks\\\\NLP\\\\Project\\\\data\\\\ideal_husband.txt'}), Document(page_content='MRS. CHEVELEY.  It was a swindle, Sir Robert.  Let us call things by\\ntheir proper names.  It makes everything simpler.  And now I am going to\\nsell you that letter, and the price I ask for it is your public support\\nof the Argentine scheme.  You made your own fortune out of one canal.\\nYou must help me and my friends to make our fortunes out of another!\\n\\nSIR ROBERT CHILTERN.  It is infamous, what you propose—infamous!', metadata={'source': 'D:\\\\Faks\\\\NLP\\\\Project\\\\data\\\\ideal_husband.txt'})]\n",
            "                         ```</s>\n",
            "                        <|user|>:\n",
            "                        Do you know anything about Mrs Cheveley's involvment with the Suez canal company?</s>\n",
            "                        <|SIR ROBERT CHILTERN|>:\n",
            "\n",
            "                        \n",
            "                        According to the passage, Mrs Cheveley was interested in International Canal schemes when Lord Radley's secretary, Lord Radley, bought the Suez Canal shares. However, there is no mention in the passage about her involvement with the Suez canal company specifically.\n",
            "0.36902716755867004 0.4257090210914612\n"
          ]
        }
      ],
      "source": [
        "book_path = \"D:\\\\Faks\\\\NLP\\\\Project\\\\data\\\\ideal_husband.txt\"\n",
        "book = Book(book_path)\n",
        "# print(book.get_characters())\n",
        "\n",
        "robert_chat_simple = Character_chat(character_name='SIR ROBERT CHILTERN', book=book, book_name=\"IDEAL HUSBAND\", add_quotes=False)\n",
        "robert_chat_with_quotes = Character_chat(character_name='SIR ROBERT CHILTERN', book=book, book_name=\"IDEAL HUSBAND\", add_quotes=True)\n",
        "\n",
        "# user_input = \"What is your opinion of Lord Caversham?\"\n",
        "user_input = \"Do you know anything about Mrs Cheveley's involvment with the Suez canal company?\"\n",
        "\n",
        "measure = get_embedding_similarity\n",
        "score1 = eval_response(user_input, robert_chat_simple, book=book, measure=get_embedding_similarity)\n",
        "score2 = eval_response(user_input, robert_chat_with_quotes, book=book, measure=get_embedding_similarity)\n",
        "print(score1, score2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
