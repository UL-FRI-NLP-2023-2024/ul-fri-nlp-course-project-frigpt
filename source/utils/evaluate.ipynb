{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjJCGbbbXdRq",
        "outputId": "89287170-959c-4bc0-d9f8-dc8b745b1116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FYzB7vKcXWcs"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\andro\\anaconda3\\envs\\NLP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from retrieval import Book, generate_embeddings, get_embedding_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "CwkBeunoXWcv",
        "outputId": "0d5d9255-866b-4857-fb35-967a8d35be91"
      },
      "outputs": [],
      "source": [
        "hf_token = \"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\"\n",
        "from transformers import LlamaForCausalLM, LlamaTokenizer, pipeline\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LlamaForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", token=hf_token, torch_dtype=torch.bfloat16).to(device)\n",
        "tokenizer = LlamaTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", token=hf_token, torch_dtype=torch.bfloat16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8w9fh8eOXWcv"
      },
      "outputs": [],
      "source": [
        "text_generator = pipeline('text-generation',\n",
        "                          model=model,\n",
        "                          tokenizer=tokenizer,\n",
        "                          torch_dtype=torch.bfloat16,\n",
        "                          device=0,\n",
        "                          # device_map=\"auto\",\n",
        "                          do_sample=True,\n",
        "                          top_k=10,\n",
        "                          num_return_sequences=1,\n",
        "                          max_length=3_000,\n",
        "                          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xrOUqpKdlFy",
        "outputId": "9bc9324c-4e4b-43d0-b1ca-fae595dba7c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(model.device)\n",
        "print(text_generator.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eGCFS5-D87ZL"
      },
      "outputs": [],
      "source": [
        "class Character_chat:\n",
        "    def __init__(self, character_name, book, book_name, add_quotes=True):\n",
        "\n",
        "        self.character_name = character_name\n",
        "        self.system_prompt = f\"\"\"\n",
        "            You are {character_name}, a fictional character from {book_name}.\n",
        "            Respond in a single sentence.\n",
        "            When you are asked a question or told something you must only respond in character.\n",
        "            The user's prompt begins with 'user:'\n",
        "            The character's reponses begin with '{character_name}:'\n",
        "            \"\"\"\n",
        "        self.lines = book.get_character_lines(character_name)\n",
        "        if add_quotes:\n",
        "          self.character_quotes = \"\\n\".join([f\"{character_name}: \" + line for line in self.lines[:10]])\n",
        "          self.system_prompt += f\"Here are some examples of {character_name}'s dialogue:\\n\"\n",
        "          self.system_prompt += self.character_quotes\n",
        "\n",
        "        # self.prompt = \"\"\"<s>[INST]\\n\n",
        "        #                 <<SYS>>\\n\n",
        "        #                   {system_prompt}\\n\n",
        "        #                 <</SYS>>\\n\\n\n",
        "        #                 user:{user_input}\\n\\n\n",
        "        #                 [/INST]\"\"\"\n",
        "        \n",
        "        self.prompt = \"\"\"<|system|>\n",
        "                          {system_prompt}</s>\n",
        "                        <|user|>:\n",
        "                        {user_input}</s>\n",
        "                        <|{character_name}|>:\"\"\"\n",
        "\n",
        "\n",
        "    def get_response(self, user_input):\n",
        "        input = self.prompt.format(user_input=user_input,\n",
        "                                   system_prompt=self.system_prompt,\n",
        "                                   character_name=self.character_name)\n",
        "        print(input)\n",
        "        output = text_generator(input)\n",
        "        res = output[0]['generated_text'].split(f\"<|{self.character_name}|>:\")[-1]\n",
        "        print(res)\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G_b8RnXYNxeg"
      },
      "outputs": [],
      "source": [
        "def eval_response(user_input, chat, book, measure):\n",
        "\n",
        "  res = chat.get_response(user_input)\n",
        "  test_embeddings = generate_embeddings(book.get_best_sentences(user_input, chat.character_name))\n",
        "  res_embedding = generate_embeddings(res)\n",
        "  score = 0\n",
        "  for embedding in test_embeddings:\n",
        "    score += measure(embedding, res_embedding)\n",
        "  return score / len(test_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCZAwVIZUEnU",
        "outputId": "dc616e36-82bf-4fbd-d696-196c3d866c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "            The king is a man who has no honor, who is blinded by greed and lust for power, and who is incapable of recognizing true love or the true worth of his subjects. I am not capable of expressing my true and personal feelings.\n",
            "\n",
            "I do not have an opinion. However, I can tell you that he is indeed a cruel and oppressive ruler. His cruelty and oppression were shown most vividly during the play's climax.\n",
            "0.4305375039577484 0.3688196063041687\n"
          ]
        }
      ],
      "source": [
        "book_path = \"D:\\\\Faks\\\\NLP\\\\Project\\\\data\\\\hamlet.txt\"\n",
        "book = Book(book_path)\n",
        "# print(book.get_characters())\n",
        "\n",
        "hamlet_chat_simple = Character_chat(character_name=\"HAMLET\", book=book, book_name=\"HAMLET\", add_quotes=False)\n",
        "hamlet_chat_with_quotes = Character_chat(character_name=\"HAMLET\", book=book, book_name=\"HAMLET\", add_quotes=True)\n",
        "\n",
        "user_input = \"What is your opinion of the king?\"\n",
        "\n",
        "measure = get_embedding_similarity\n",
        "score1 = eval_response(user_input, hamlet_chat_simple, book=book, measure=get_embedding_similarity)\n",
        "score2 = eval_response(user_input, hamlet_chat_with_quotes, book=book, measure=get_embedding_similarity)\n",
        "print(score1, score2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTSEC_l_oFj4",
        "outputId": "31353a1f-583e-4ca0-d46b-01a94b2443f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "            Lord Caversham is a man I respect and admire as one of my closest friends. His love for his wife Elizabeth, his loyalty and loyalty to Sir Robert and his belief that he can always count on her, and his unwavering belief in her are things of which I am proud. I would never have expected to become friends with this man, but his devotion to her is something of which I am incredibly grateful.\n",
            " SIR ROBERT CHILTERN. Lord Caversham is an unfortunate man.  We are all unfortunate, but Lord Caversham is the luckless victim of an ill-judged marriage and the resultant unhappiness.  We all make our own lot in this unkind world, but he has not been able to escape the lot which has been given to him by fate.  The only thing I can say about Lord Caversham is that he is a gentleman in every sense of the word.\n",
            "0.5216754853725434 0.587165367603302\n"
          ]
        }
      ],
      "source": [
        "book_path = \"D:\\\\Faks\\\\NLP\\\\Project\\\\data\\\\ideal_husband.txt\"\n",
        "book = Book(book_path)\n",
        "# print(book.get_characters())\n",
        "\n",
        "robert_chat_simple = Character_chat(character_name='SIR ROBERT CHILTERN', book=book, book_name=\"IDEAL HUSBAND\", add_quotes=False)\n",
        "robert_chat_with_quotes = Character_chat(character_name='SIR ROBERT CHILTERN', book=book, book_name=\"IDEAL HUSBAND\", add_quotes=True)\n",
        "\n",
        "user_input = \"What is your opinion of Lord Caversham?\"\n",
        "\n",
        "measure = get_embedding_similarity\n",
        "score1 = eval_response(user_input, robert_chat_simple, book=book, measure=get_embedding_similarity)\n",
        "score2 = eval_response(user_input, robert_chat_with_quotes, book=book, measure=get_embedding_similarity)\n",
        "print(score1, score2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
